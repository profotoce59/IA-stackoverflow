{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26232dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk, string\n",
    "from bs4 import BeautifulSoup\n",
    "from torchtext.data import get_tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c201b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "def custom_read_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.dropna(subset=['tags','title'])\n",
    "    df['tags'] = df['tags'].apply(custom_tolist)\n",
    "    return df\n",
    "def custom_tolist(a): ##remove parentheses\n",
    "    newstr = a.replace(\"[\", \"\")\n",
    "    newstr = newstr.replace(\" \", \"\")\n",
    "    newstr = newstr.replace(\"]\", \"\")\n",
    "    newstr = newstr.replace(\"'\", \"\")\n",
    "    a = newstr.split(',')\n",
    "    return a\n",
    "def remove_html(body):\n",
    "    soup = BeautifulSoup(body)\n",
    "    return soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0e1a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean(commentaire): \n",
    "            \n",
    "    # Contractions\n",
    "    commentaire = re.sub(r\"he's\", \"he is\", commentaire)\n",
    "    commentaire = re.sub(r\"there's\", \"there is\", commentaire)\n",
    "    commentaire = re.sub(r\"We're\", \"We are\", commentaire)\n",
    "    commentaire = re.sub(r\"That's\", \"That is\", commentaire)\n",
    "    commentaire = re.sub(r\"won't\", \"will not\", commentaire)\n",
    "    commentaire = re.sub(r\"they're\", \"they are\", commentaire)\n",
    "    commentaire = re.sub(r\"Can't\", \"Cannot\", commentaire)\n",
    "    commentaire = re.sub(r\"wasn't\", \"was not\", commentaire)\n",
    "    commentaire = re.sub(r\"don\\x89Ûªt\", \"do not\", commentaire)\n",
    "    commentaire = re.sub(r\"aren't\", \"are not\", commentaire)\n",
    "    commentaire = re.sub(r\"isn't\", \"is not\", commentaire)\n",
    "    commentaire = re.sub(r\"What's\", \"What is\", commentaire)\n",
    "    commentaire = re.sub(r\"haven't\", \"have not\", commentaire)\n",
    "    commentaire = re.sub(r\"hasn't\", \"has not\", commentaire)\n",
    "    commentaire = re.sub(r\"There's\", \"There is\", commentaire)\n",
    "    commentaire = re.sub(r\"He's\", \"He is\", commentaire)\n",
    "    commentaire = re.sub(r\"It's\", \"It is\", commentaire)\n",
    "    commentaire = re.sub(r\"You're\", \"You are\", commentaire)\n",
    "    commentaire = re.sub(r\"I'M\", \"I am\", commentaire)\n",
    "    commentaire = re.sub(r\"shouldn't\", \"should not\", commentaire)\n",
    "    commentaire = re.sub(r\"wouldn't\", \"would not\", commentaire)\n",
    "    commentaire = re.sub(r\"i'm\", \"I am\", commentaire)\n",
    "    commentaire = re.sub(r\"I\\x89Ûªm\", \"I am\", commentaire)\n",
    "    commentaire = re.sub(r\"I'm\", \"I am\", commentaire)\n",
    "    commentaire = re.sub(r\"Isn't\", \"is not\", commentaire)\n",
    "    commentaire = re.sub(r\"Here's\", \"Here is\", commentaire)\n",
    "    commentaire = re.sub(r\"you've\", \"you have\", commentaire)\n",
    "    commentaire = re.sub(r\"you\\x89Ûªve\", \"you have\", commentaire)\n",
    "    commentaire = re.sub(r\"we're\", \"we are\", commentaire)\n",
    "    commentaire = re.sub(r\"what's\", \"what is\", commentaire)\n",
    "    commentaire = re.sub(r\"couldn't\", \"could not\", commentaire)\n",
    "    commentaire = re.sub(r\"we've\", \"we have\", commentaire)\n",
    "    commentaire = re.sub(r\"it\\x89Ûªs\", \"it is\", commentaire)\n",
    "    commentaire = re.sub(r\"doesn\\x89Ûªt\", \"does not\", commentaire)\n",
    "    commentaire = re.sub(r\"It\\x89Ûªs\", \"It is\", commentaire)\n",
    "    commentaire = re.sub(r\"Here\\x89Ûªs\", \"Here is\", commentaire)\n",
    "    commentaire = re.sub(r\"who's\", \"who is\", commentaire)\n",
    "    commentaire = re.sub(r\"I\\x89Ûªve\", \"I have\", commentaire)\n",
    "    commentaire = re.sub(r\"y'all\", \"you all\", commentaire)\n",
    "    commentaire = re.sub(r\"can\\x89Ûªt\", \"cannot\", commentaire)\n",
    "    commentaire = re.sub(r\"would've\", \"would have\", commentaire)\n",
    "    commentaire = re.sub(r\"it'll\", \"it will\", commentaire)\n",
    "    commentaire = re.sub(r\"we'll\", \"we will\", commentaire)\n",
    "    commentaire = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", commentaire)\n",
    "    commentaire = re.sub(r\"We've\", \"We have\", commentaire)\n",
    "    commentaire = re.sub(r\"he'll\", \"he will\", commentaire)\n",
    "    commentaire = re.sub(r\"Y'all\", \"You all\", commentaire)\n",
    "    commentaire = re.sub(r\"Weren't\", \"Were not\", commentaire)\n",
    "    commentaire = re.sub(r\"Didn't\", \"Did not\", commentaire)\n",
    "    commentaire = re.sub(r\"they'll\", \"they will\", commentaire)\n",
    "    commentaire = re.sub(r\"they'd\", \"they would\", commentaire)\n",
    "    commentaire = re.sub(r\"DON'T\", \"DO NOT\", commentaire)\n",
    "    commentaire = re.sub(r\"That\\x89Ûªs\", \"That is\", commentaire)\n",
    "    commentaire = re.sub(r\"they've\", \"they have\", commentaire)\n",
    "    commentaire = re.sub(r\"i'd\", \"I would\", commentaire)\n",
    "    commentaire = re.sub(r\"should've\", \"should have\", commentaire)\n",
    "    commentaire = re.sub(r\"You\\x89Ûªre\", \"You are\", commentaire)\n",
    "    commentaire = re.sub(r\"where's\", \"where is\", commentaire)\n",
    "    commentaire = re.sub(r\"Don\\x89Ûªt\", \"Do not\", commentaire)\n",
    "    commentaire = re.sub(r\"we'd\", \"we would\", commentaire)\n",
    "    commentaire = re.sub(r\"i'll\", \"I will\", commentaire)\n",
    "    commentaire = re.sub(r\"weren't\", \"were not\", commentaire)\n",
    "    commentaire = re.sub(r\"They're\", \"They are\", commentaire)\n",
    "    commentaire = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", commentaire)\n",
    "    commentaire = re.sub(r\"you\\x89Ûªll\", \"you will\", commentaire)\n",
    "    commentaire = re.sub(r\"I\\x89Ûªd\", \"I would\", commentaire)\n",
    "    commentaire = re.sub(r\"let's\", \"let us\", commentaire)\n",
    "    commentaire = re.sub(r\"it's\", \"it is\", commentaire)\n",
    "    commentaire = re.sub(r\"can't\", \"cannot\", commentaire)\n",
    "    commentaire = re.sub(r\"don't\", \"do not\", commentaire)\n",
    "    commentaire = re.sub(r\"you're\", \"you are\", commentaire)\n",
    "    commentaire = re.sub(r\"i've\", \"I have\", commentaire)\n",
    "    commentaire = re.sub(r\"that's\", \"that is\", commentaire)\n",
    "    commentaire = re.sub(r\"i'll\", \"I will\", commentaire)\n",
    "    commentaire = re.sub(r\"doesn't\", \"does not\", commentaire)\n",
    "    commentaire = re.sub(r\"i'd\", \"I would\", commentaire)\n",
    "    commentaire = re.sub(r\"didn't\", \"did not\", commentaire)\n",
    "    commentaire = re.sub(r\"ain't\", \"am not\", commentaire)\n",
    "    commentaire = re.sub(r\"you'll\", \"you will\", commentaire)\n",
    "    commentaire = re.sub(r\"I've\", \"I have\", commentaire)\n",
    "    commentaire = re.sub(r\"Don't\", \"do not\", commentaire)\n",
    "    commentaire = re.sub(r\"I'll\", \"I will\", commentaire)\n",
    "    commentaire = re.sub(r\"I'd\", \"I would\", commentaire)\n",
    "    commentaire = re.sub(r\"Let's\", \"Let us\", commentaire)\n",
    "    commentaire = re.sub(r\"you'd\", \"You would\", commentaire)\n",
    "    commentaire = re.sub(r\"It's\", \"It is\", commentaire)\n",
    "    commentaire = re.sub(r\"Ain't\", \"am not\", commentaire)\n",
    "    commentaire = re.sub(r\"Haven't\", \"Have not\", commentaire)\n",
    "    commentaire = re.sub(r\"Could've\", \"Could have\", commentaire)\n",
    "    commentaire = re.sub(r\"youve\", \"you have\", commentaire)  \n",
    "    commentaire = re.sub(r\"donå«t\", \"do not\", commentaire)  \n",
    "    \n",
    "    commentaire = re.sub(r\"some1\", \"someone\", commentaire)\n",
    "    commentaire = re.sub(r\"yrs\", \"years\", commentaire)\n",
    "    commentaire = re.sub(r\"hrs\", \"hours\", commentaire)\n",
    "    commentaire = re.sub(r\"2morow|2moro\", \"tomorrow\", commentaire)\n",
    "    commentaire = re.sub(r\"2day\", \"today\", commentaire)\n",
    "    commentaire = re.sub(r\"4got|4gotten\", \"forget\", commentaire)\n",
    "    commentaire = re.sub(r\"b-day|bday\", \"b-day\", commentaire)\n",
    "    commentaire = re.sub(r\"mother's\", \"mother\", commentaire)\n",
    "    commentaire = re.sub(r\"mom's\", \"mom\", commentaire)\n",
    "    commentaire = re.sub(r\"dad's\", \"dad\", commentaire)\n",
    "    commentaire = re.sub(r\"hahah|hahaha|hahahaha\", \"haha\", commentaire)\n",
    "    commentaire = re.sub(r\"lmao|lolz|rofl\", \"lol\", commentaire)\n",
    "    commentaire = re.sub(r\"thanx|thnx\", \"thanks\", commentaire)\n",
    "    commentaire = re.sub(r\"goood\", \"good\", commentaire)\n",
    "    commentaire = re.sub(r\"some1\", \"someone\", commentaire)\n",
    "    commentaire = re.sub(r\"some1\", \"someone\", commentaire)\n",
    "    # Character entity references\n",
    "    commentaire = re.sub(r\">\", \">\", commentaire)\n",
    "    commentaire = re.sub(r\"<\", \"<\", commentaire)\n",
    "    commentaire = re.sub(r\"&\", \"&\", commentaire)\n",
    "    # Typos, slang and informal abbreviations\n",
    "    commentaire = re.sub(r\"w/e\", \"whatever\", commentaire)\n",
    "    commentaire = re.sub(r\"w/\", \"with\", commentaire)\n",
    "    commentaire = re.sub(r\"<3\", \"love\", commentaire)\n",
    "    # Urls\n",
    "    commentaire = re.sub(r\"http\\S+\", \"\", commentaire)\n",
    "    # Numbers\n",
    "    commentaire = re.sub(r'[0-9]', '', commentaire)\n",
    "    # Eliminating the mentions\n",
    "    commentaire = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", commentaire)\n",
    "    # Remove punctuation and special chars (keep '#','+')\n",
    "    for p in string.punctuation:\n",
    "        if p in ['#','+']:\n",
    "            continue\n",
    "        else :\n",
    "            commentaire = commentaire.replace(p, '')  \n",
    "    \n",
    "    # Tokenize\n",
    "    #commentaire_words = tokenizer1.tokenize(commentaire)\n",
    "    \n",
    "    # Eliminating the word if its length is less than 3 for now no if we have c, c# r...\n",
    "\n",
    "    #lower\n",
    "    commentaire = commentaire.lower()     \n",
    "    return commentaire\n",
    "\n",
    "\n",
    "    variable_name = \"\"\n",
    "abbreviations = {\n",
    "    \"$\" : \" dollar \",\n",
    "    \"€\" : \" euro \",\n",
    "    \"4ao\" : \"for adults only\",\n",
    "    \"a.m\" : \"before midday\",\n",
    "    \"a3\" : \"anytime anywhere anyplace\",\n",
    "    \"aamof\" : \"as a matter of fact\",\n",
    "    \"acct\" : \"account\",\n",
    "    \"adih\" : \"another day in hell\",\n",
    "    \"afaic\" : \"as far as i am concerned\",\n",
    "    \"afaict\" : \"as far as i can tell\",\n",
    "    \"afaik\" : \"as far as i know\",\n",
    "    \"afair\" : \"as far as i remember\",\n",
    "    \"afk\" : \"away from keyboard\",\n",
    "    \"app\" : \"application\",\n",
    "    \"approx\" : \"approximately\",\n",
    "    \"apps\" : \"applications\",\n",
    "    \"asap\" : \"as soon as possible\",\n",
    "    \"asl\" : \"age, sex, location\",\n",
    "    \"atk\" : \"at the keyboard\",\n",
    "    \"ave.\" : \"avenue\",\n",
    "    \"aymm\" : \"are you my mother\",\n",
    "    \"ayor\" : \"at your own risk\", \n",
    "    \"b&b\" : \"bed and breakfast\",\n",
    "    \"b+b\" : \"bed and breakfast\",\n",
    "    \"b.c\" : \"before christ\",\n",
    "    \"b2b\" : \"business to business\",\n",
    "    \"b2c\" : \"business to customer\",\n",
    "    \"b4\" : \"before\",\n",
    "    \"b4n\" : \"bye for now\",\n",
    "    \"b@u\" : \"back at you\",\n",
    "    \"bae\" : \"before anyone else\",\n",
    "    \"bak\" : \"back at keyboard\",\n",
    "    \"bbbg\" : \"bye bye be good\",\n",
    "    \"bbc\" : \"british broadcasting corporation\",\n",
    "    \"bbias\" : \"be back in a second\",\n",
    "    \"bbl\" : \"be back later\",\n",
    "    \"bbs\" : \"be back soon\",\n",
    "    \"be4\" : \"before\",\n",
    "    \"bfn\" : \"bye for now\",\n",
    "    \"blvd\" : \"boulevard\",\n",
    "    \"bout\" : \"about\",\n",
    "    \"brb\" : \"be right back\",\n",
    "    \"bros\" : \"brothers\",\n",
    "    \"brt\" : \"be right there\",\n",
    "    \"bsaaw\" : \"big smile and a wink\",\n",
    "    \"btw\" : \"by the way\",\n",
    "    \"bwl\" : \"bursting with laughter\",\n",
    "    \"c/o\" : \"care of\",\n",
    "    \"cet\" : \"central european time\",\n",
    "    \"cf\" : \"compare\",\n",
    "    \"cia\" : \"central intelligence agency\",\n",
    "    \"csl\" : \"can not stop laughing\",\n",
    "    \"cu\" : \"see you\",\n",
    "    \"cul8r\" : \"see you later\",\n",
    "    \"cv\" : \"curriculum vitae\",\n",
    "    \"cwot\" : \"complete waste of time\",\n",
    "    \"cya\" : \"see you\",\n",
    "    \"cyt\" : \"see you tomorrow\",\n",
    "    \"dae\" : \"does anyone else\",\n",
    "    \"dbmib\" : \"do not bother me i am busy\",\n",
    "    \"diy\" : \"do it yourself\",\n",
    "    \"dm\" : \"direct message\",\n",
    "    \"dwh\" : \"during work hours\",\n",
    "    \"e123\" : \"easy as one two three\",\n",
    "    \"eet\" : \"eastern european time\",\n",
    "    \"eg\" : \"example\",\n",
    "    \"embm\" : \"early morning business meeting\",\n",
    "    \"encl\" : \"enclosed\",\n",
    "    \"encl.\" : \"enclosed\",\n",
    "    \"etc\" : \"and so on\",\n",
    "    \"faq\" : \"frequently asked questions\",\n",
    "    \"fawc\" : \"for anyone who cares\",\n",
    "    \"fb\" : \"facebook\",\n",
    "    \"fc\" : \"fingers crossed\",\n",
    "    \"fig\" : \"figure\",\n",
    "    \"fimh\" : \"forever in my heart\", \n",
    "    \"ft.\" : \"feet\",\n",
    "    \"ft\" : \"featuring\",\n",
    "    \"ftl\" : \"for the loss\",\n",
    "    \"ftw\" : \"for the win\",\n",
    "    \"fwiw\" : \"for what it is worth\",\n",
    "    \"fyi\" : \"for your information\",\n",
    "    \"g9\" : \"genius\",\n",
    "    \"gahoy\" : \"get a hold of yourself\",\n",
    "    \"gal\" : \"get a life\",\n",
    "    \"gcse\" : \"general certificate of secondary education\",\n",
    "    \"gfn\" : \"gone for now\",\n",
    "    \"gg\" : \"good game\",\n",
    "    \"gl\" : \"good luck\",\n",
    "    \"glhf\" : \"good luck have fun\",\n",
    "    \"gmt\" : \"greenwich mean time\",\n",
    "    \"gmta\" : \"great minds think alike\",\n",
    "    \"gn\" : \"good night\",\n",
    "    \"g.o.a.t\" : \"greatest of all time\",\n",
    "    \"goat\" : \"greatest of all time\",\n",
    "    \"goi\" : \"get over it\",\n",
    "    \"gps\" : \"global positioning system\",\n",
    "    \"gr8\" : \"great\",\n",
    "    \"gratz\" : \"congratulations\",\n",
    "    \"gyal\" : \"girl\",\n",
    "    \"h&c\" : \"hot and cold\",\n",
    "    \"hp\" : \"horsepower\",\n",
    "    \"hr\" : \"hour\",\n",
    "    \"hrh\" : \"his royal highness\",\n",
    "    \"ht\" : \"height\",\n",
    "    \"ibrb\" : \"i will be right back\",\n",
    "    \"ic\" : \"i see\",\n",
    "    \"icq\" : \"i seek you\",\n",
    "    \"icymi\" : \"in case you missed it\",\n",
    "    \"idc\" : \"i do not care\",\n",
    "    \"idgadf\" : \"i do not give a damn fuck\",\n",
    "    \"idgaf\" : \"i do not give a fuck\",\n",
    "    \"idk\" : \"i do not know\",\n",
    "    \"ie\" : \"that is\",\n",
    "    \"i.e\" : \"that is\",\n",
    "    \"ifyp\" : \"i feel your pain\",\n",
    "    \"IG\" : \"instagram\",\n",
    "    \"iirc\" : \"if i remember correctly\",\n",
    "    \"ilu\" : \"i love you\",\n",
    "    \"ily\" : \"i love you\",\n",
    "    \"imho\" : \"in my humble opinion\",\n",
    "    \"imo\" : \"in my opinion\",\n",
    "    \"imu\" : \"i miss you\",\n",
    "    \"iow\" : \"in other words\",\n",
    "    \"irl\" : \"in real life\",\n",
    "    \"j4f\" : \"just for fun\",\n",
    "    \"jic\" : \"just in case\",\n",
    "    \"jk\" : \"just kidding\",\n",
    "    \"jsyk\" : \"just so you know\",\n",
    "    \"l8r\" : \"later\",\n",
    "    \"lb\" : \"pound\",\n",
    "    \"lbs\" : \"pounds\",\n",
    "    \"ldr\" : \"long distance relationship\",\n",
    "    \"lmao\" : \"laugh my ass off\",\n",
    "    \"lmfao\" : \"laugh my fucking ass off\",\n",
    "    \"lol\" : \"laughing out loud\",\n",
    "    \"ltd\" : \"limited\",\n",
    "    \"ltns\" : \"long time no see\",\n",
    "    \"m8\" : \"mate\",\n",
    "    \"mf\" : \"motherfucker\",\n",
    "    \"mfs\" : \"motherfuckers\",\n",
    "    \"mfw\" : \"my face when\",\n",
    "    \"mofo\" : \"motherfucker\",\n",
    "    \"mph\" : \"miles per hour\",\n",
    "    \"mr\" : \"mister\",\n",
    "    \"mrw\" : \"my reaction when\",\n",
    "    \"ms\" : \"miss\",\n",
    "    \"mte\" : \"my thoughts exactly\",\n",
    "    \"nagi\" : \"not a good idea\",\n",
    "    \"nbc\" : \"national broadcasting company\",\n",
    "    \"nbd\" : \"not big deal\",\n",
    "    \"nfs\" : \"not for sale\",\n",
    "    \"ngl\" : \"not going to lie\",\n",
    "    \"nhs\" : \"national health service\",\n",
    "    \"nrn\" : \"no reply necessary\",\n",
    "    \"nsfl\" : \"not safe for life\",\n",
    "    \"nsfw\" : \"not safe for work\",\n",
    "    \"nth\" : \"nice to have\",\n",
    "    \"nvr\" : \"never\",\n",
    "    \"nyc\" : \"new york city\",\n",
    "    \"oc\" : \"original content\",\n",
    "    \"og\" : \"original\",\n",
    "    \"ohp\" : \"overhead projector\",\n",
    "    \"oic\" : \"oh i see\",\n",
    "    \"omdb\" : \"over my dead body\",\n",
    "    \"omg\" : \"oh my god\",\n",
    "    \"omw\" : \"on my way\",\n",
    "    \"p.a\" : \"per annum\",\n",
    "    \"p.m\" : \"after midday\",\n",
    "    \"pm\" : \"prime minister\",\n",
    "    \"poc\" : \"people of color\",\n",
    "    \"pov\" : \"point of view\",\n",
    "    \"pp\" : \"pages\",\n",
    "    \"ppl\" : \"people\",\n",
    "    \"prw\" : \"parents are watching\",\n",
    "    \"ps\" : \"postscript\",\n",
    "    \"pt\" : \"point\",\n",
    "    \"ptb\" : \"please text back\",\n",
    "    \"pto\" : \"please turn over\",\n",
    "    \"qpsa\" : \"what happens\", \n",
    "    \"ratchet\" : \"rude\",\n",
    "    \"rbtl\" : \"read between the lines\",\n",
    "    \"rlrt\" : \"real life retweet\", \n",
    "    \"rofl\" : \"rolling on the floor laughing\",\n",
    "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
    "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
    "    \"rt\" : \"retweet\",\n",
    "    \"ruok\" : \"are you ok\",\n",
    "    \"sfw\" : \"safe for work\",\n",
    "     \"sk8\" : \"skate\",\n",
    "    \"smh\" : \"shake my head\",\n",
    "    \"sq\" : \"square\",\n",
    "    \"srsly\" : \"seriously\", \n",
    "    \"ssdd\" : \"same stuff different day\",\n",
    "    \"tbh\" : \"to be honest\",\n",
    "    \"tbs\" : \"tablespooful\",\n",
    "    \"tbsp\" : \"tablespooful\",\n",
    "    \"tfw\" : \"that feeling when\",\n",
    "    \"thks\" : \"thank you\",\n",
    "    \"tho\" : \"though\",\n",
    "    \"thx\" : \"thank you\",\n",
    "    \"tia\" : \"thanks in advance\",\n",
    "    \"til\" : \"today i learned\",\n",
    "    \"tl;dr\" : \"too long i did not read\",\n",
    "    \"tldr\" : \"too long i did not read\",\n",
    "    \"tmb\" : \"tweet me back\",\n",
    "    \"tntl\" : \"trying not to laugh\",\n",
    "    \"ttyl\" : \"talk to you later\",\n",
    "    \"u\" : \"you\",\n",
    "    \"u2\" : \"you too\",\n",
    "    \"u4e\" : \"yours for ever\",\n",
    "    \"utc\" : \"coordinated universal time\",\n",
    "    \"w/\" : \"with\",\n",
    "    \"w/o\" : \"without\",\n",
    "    \"w8\" : \"wait\",\n",
    "    \"wassup\" : \"what is up\",\n",
    "    \"wb\" : \"welcome back\",\n",
    "    \"wtf\" : \"what the fuck\",\n",
    "    \"wtg\" : \"way to go\",\n",
    "    \"wtpa\" : \"where the party at\",\n",
    "    \"wuf\" : \"where are you from\",\n",
    "    \"wuzup\" : \"what is up\",\n",
    "    \"wywh\" : \"wish you were here\",\n",
    "    \"yd\" : \"yard\",\n",
    "    \"ygtr\" : \"you got that right\",\n",
    "    \"ynk\" : \"you never know\",\n",
    "    \"zzz\" : \"sleeping bored and tired\"\n",
    "}\n",
    "\n",
    "def convert_abbrev_in_text(commentaire): #pas encore utilisé\n",
    "    t=[]\n",
    "    words=commentaire.split()\n",
    "    t = [abbreviations[w.lower()] if w.lower() in abbreviations.keys() else w for w in words]\n",
    "    print(t)\n",
    "    return ''.join(t) \n",
    "\n",
    "def prepare_string(commentaire):\n",
    "    commentaire = clean(commentaire)\n",
    "    #commentaire = commentaire.split(' ')\n",
    "    #commentaire = convert_abbrev_in_text(commentaire)\n",
    "    #print(commentaire)\n",
    "    return commentaire\n",
    "def to_list_of_word(commentaire,tokenizer):\n",
    "    commentaire = re.sub(\"  \",\" \", commentaire) #remove double space\n",
    "    comm = tokenizer(commentaire)\n",
    "    #on enlève tous les mots de moins de 3 lettres\n",
    "    index = 0\n",
    "    while index<len(comm):\n",
    "        if((len(comm[index]) <3) and comm[index] not in ['c#','c','js','r','go','n','os','ng']):\n",
    "            comm.remove(comm[index])\n",
    "            index-=1\n",
    "        index +=1\n",
    "    comm = ' '.join(comm)\n",
    "    return comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04e3e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "data = custom_read_csv(\"data/second_question.csv\")\n",
    "data['body'] = data['body'].apply(remove_html)\n",
    "data['body'] = data['body'].apply(prepare_string)\n",
    "data['body'] = data['body'].apply(to_list_of_word,tokenizer=tokenizer)\n",
    "print(data['body'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9036b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "commentaires = (data['body'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0bcf4a",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e97926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfIdfVectorizer = TfidfVectorizer()\n",
    "\n",
    "X = tfIdfVectorizer.fit_transform(commentaires).toarray()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab96b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tags_list = data['tags'][:1000].explode().unique()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6b1bb8",
   "metadata": {},
   "source": [
    "#En classification de labels avec des arbres de décision on ne peut pas prédire plusieurs tags pour une donnée. On va donc devoir donner un seul label  à prédire pour notre randomForest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b15faf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_randf = data.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da313d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_tag(tags_list):\n",
    "    return tags_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c845abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_rand_tag(tags_list):\n",
    "    a=random.randrange(0, len(tags_list))\n",
    "    return tags_list[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db47e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_randf['tags'] = df_randf['tags'].apply(get_rand_tag)\n",
    "len(df_randf['tags'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a90baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(df_randf['tags'])\n",
    "#print(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print(X_test[0:1][0][0:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd34daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_classifier = RandomForestClassifier(n_estimators=15, random_state=0)  \n",
    "text_classifier.fit(X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df71c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd07a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a721e130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaa6b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(predictions)\n",
    "pred_dataframe = pd.DataFrame(data=predictions, columns=y_test.columns)\n",
    "result1 = y_test.idxmax(axis=1)\n",
    "result2 = pred_dataframe.idxmax(axis=1)\n",
    "print(result1.value_counts())\n",
    "print(result2.value_counts())\n",
    "result1 = result1.to_list()\n",
    "result2 = result2.to_list()\n",
    "for idx in range(len(result1)):\n",
    "    if(result1[idx] is not  result2[idx]):\n",
    "        print(result1[idx])\n",
    "        print(result2[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fdf785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
